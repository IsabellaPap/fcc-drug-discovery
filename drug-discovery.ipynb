{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Hi everyone!\n",
    "\n",
    "This is a comprehensive report of a beginner level Bioiformatics with Python course on [Drug Discovery with Using Machine Learning and Data Analysis.](https://www.youtube.com/watch?v=jBlTQjcKuaY) The course was found on [freeCodeCamp](https://www.freecodecamp.org/news/python-for-bioinformatics-use-machine-learning-and-data-analysis-for-drug-discovery/), where you can find an abundance of free resources on data analysis and machine learning. I was very lucky to find one with applications in Bioinformatics. It is addressed to beginners, and prior knowledge of Biology or Bioinformatics is not required.\n",
    "\n",
    "This guide I hope to be able to add more details on each step of the Data Analysis process, thus making this even more beginner friendly, if you are like me and just jumping into Data Analysis and Machine Learning. Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Acquiring the data\n",
    "\n",
    "For this project we will be using the The [*ChEMBL Database*](https://www.ebi.ac.uk/chembl/), which is a database that contains curated bioactivity data of more than 2 million compounds.\n",
    "\n",
    "In order to access these data, we need to install the web service package that the ChEMBL Database kindly provides.\n",
    "\n",
    "In order to do so, we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install chembl_webresource_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the ChEMPL Database\n",
    "\n",
    "If you visit The [*ChEMBL Database*](https://www.ebi.ac.uk/chembl/) website, you will come upon an interface which you can use to search for and filter various entries. For example, you can input the name of a disease in the search box (like Alzheimer's), and you will receive a plethora of results. If you filter the results to show only \"Targets\", you will get the *Target Proteins (or organisms)* associated to the disease.\n",
    "\n",
    "**Target Proteins** are those that are addressed and controlled by **biologically active compounds**, meaning drugs. These are the proteins on which the drug will induce a *modulatory* activity, which can be activating or inhibiting it essentially.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the client\n",
    "\n",
    "To be able to use the client now that we installed it, we need to import it into our python code. If you don't have pandas already installed in your environment, now is the time to do it! We are going to need this library for sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from chembl_webresource_client.new_client import new_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for target protein\n",
    "\n",
    "Just as we used the website of the ChEMBL database before, we can perform the same actions through the client we installed and imported at the start of this step. Convenient *huh*? In this example we can search for any virus or disease to find the targets and other useful data.\n",
    "\n",
    "So in that case we could search for \"coronavirus\" and choose a target from the results, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target search for coronavirus\n",
    "\n",
    "target = new_client.target\n",
    "target_query = target.search('coronavirus')\n",
    "\n",
    "# using pandas to turn this into a handy dataframe\n",
    "targets = pd.DataFrame.from_dict(target_query)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we are going to cheat it a bit, knowing the name of the protein we are looking for, so we will search for it by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target search for Acetylcholinesterase\n",
    "\n",
    "target = new_client.target\n",
    "target_query = target.search('acetylcholinesterase')\n",
    "\n",
    "# using pandas to turn this into a handy dataframe\n",
    "targets = pd.DataFrame.from_dict(target_query)\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and retrieve bioactivity data for one single-protein target: Acetylcholinesterase  (1st entry)\n",
    "\n",
    "In this step we use a single-protein target for which we will retrieve bioactivity data. In our case we choose the Human Acetylcholinesterase protein. To proceed we need to retrieve and store the `target_chembl_id` which is the unique identifier for this protein, so we don't have to go around calling it \"single-protein target, Acetylcholinesterase of the Homo sapiens organism\", as if it's royalty from medieval times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_target = targets.target_chembl_id[0]\n",
    "selected_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select only a specific type of activity, which bares the code \"IC50\". The reason we filter by `standard_type` is that it ensures that the bioactivity units will be uniform, so we will not have to deal with such incosistencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = new_client.activity\n",
    "res = activity.filter(target_chembl_id=selected_target).filter(standard_type=\"IC50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "\n",
    "We will save this bioactivity data into a csv, to be used later as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('acetylcholinesterase_01_bioactivity_data_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Pre-processing our data\n",
    "\n",
    "Now that we have retrieved our data, into a dataframe and also a csv, we can start processing them to get our own unique and cohesive DataFrame to work on.\n",
    "\n",
    "## Handling Missing Data\n",
    "The first step in the cleaning process, is getting rid of entries that have empty `standard_value` or `canonical_smiles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('acetylcholinesterase_01_bioactivity_data_raw.csv')\n",
    "df2 = df[df.standard_value.notna()]\n",
    "df2 = df2[df.canonical_smiles.notna()]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how we dropped from `8832` entries to `7547`. Now we will check if there are duplicates for `canonical_smiles`.\n",
    "\n",
    "We call the `unique()` function to check this. If the output of unique values is smaller than the number of rows, then we will know that we have duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2.canonical_smiles.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently the unique values are less than `7547`, so we will go ahead and drop the duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_nr = df2.drop_duplicates(['canonical_smiles'])\n",
    "df2_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Labeling compounds as either being active, inactive or intermediate**\n",
    " We will label the data based on their ``standard value`` which is in the IC50 unit. Compounds having values of less than 1000 nM will be considered to be **active** while those greater than 10,000 nM will be considered to be **inactive**. As for those values in between 1,000 and 10,000 nM will be referred to as **intermediate**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioactivity_class = []\n",
    "for i in df2_nr.standard_value:\n",
    "  if float(i) >= 10000:\n",
    "    bioactivity_class.append(\"inactive\")\n",
    "  elif float(i) <= 1000:\n",
    "    bioactivity_class.append(\"active\")\n",
    "  else:\n",
    "    bioactivity_class.append(\"intermediate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the 3 columns (molecule_chembl_id,canonical_smiles,standard_value) and bioactivity_class into a DataFrame\n",
    "\n",
    "As we see above, it is quite hard to check all 46 columns of the table, so we will need to combine the columns we are studying, into one DataFrame.\n",
    "\n",
    "### The molecule_chembl_id\n",
    "Remember how we mentioned **Target Proteins**, and how they are the ones controlled and affected by an active compound? Well the list of molecules that we are about to iterate are those compounds. Compounds and molecules are therefore the same thing, and in our case are responsible for activating or inhibiting the target. For the sake of minimum redundancy, we will only keep one entry of each compound in our dataframe. The ``molecule_chembl_id`` is a unique identifier for these compounds.\n",
    "\n",
    "We select it among the `canonical_smiles` and `standard_value` (IC50), to finally concatinate it with the `bioactivity_class` list from above, where we labeled them based on their IC50 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = ['molecule_chembl_id','canonical_smiles','standard_value']\n",
    "df3 = df2_nr[selection]\n",
    "\n",
    "pd.concat([df3,pd.Series(bioactivity_class)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small note: we had to convert the `bioactivity_class` into a Series or else it could not be concatinated with the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('acetylcholinesterase_02_bioactivity_data_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('acetylcholinesterase_02_bioactivity_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis refers to all the investigation we perform on a dataset, whether that be spotting anomalies, testing a hypothesis, discovering patterns, or anything of the sort. In the scope of this step of the project, we will calculate descriptors. Descriptors are mathematical function that map datasets to a fixed-size vector. And because it took me reading that sentence 3 times to understand it, descriptors are calculated so you can cluster/classify/visualise your data more easily through the output of the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing conda and rdkit\n",
    "\n",
    "I have provided an additional guide to installation for a different system than the one provided originally in the course.\n",
    "**Important Note** : changes to the $PATH variable done in Jupyter cells don't persist, so it is better to add conda to your path through the terminal directly. To do so type this *after* installing miniconda3 (so after the bash command):\n",
    "\n",
    "----\n",
    "```\n",
    "echo 'export PATH=\"$HOME/miniconda3/bin:$PATH\"' >> ~/.zshrc\n",
    "source ~/.zshrc\n",
    "```\n",
    "----\n",
    "Change `zshrc` with `bashrc` if that's what you're using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Linux with Python 3.7\n",
    "# ! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
    "# ! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
    "# ! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
    "# ! conda install -c rdkit rdkit -y\n",
    "# import sys\n",
    "# sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "\n",
    "# for MacOS with Python 3.11.3 (I use zsh, modify PATH related command if you use bash)\n",
    "\n",
    "! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n",
    "! bash Miniconda3-latest-MacOSX-x86_64.sh -b -p $HOME/miniconda3\n",
    "# add conda to your path!\n",
    "! conda install -c rdkit rdkit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
